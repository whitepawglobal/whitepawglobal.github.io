[{"categories":["nlp"],"content":"Step-by-step walkthrough on lip-syncing with Wav2Lip","date":"2022-10-10","objectID":"/deepfake-audio-with-wav2lip/","tags":["deepfake","lipsync","python"],"title":"Deepfake Audio with Wav2Lip","uri":"/deepfake-audio-with-wav2lip/"},{"categories":["nlp"],"content":"Overview of Deepfake Technology Deepfake is a technology that creates synthesis media with a subfield of Machine Learning - Deep Learning. Photo by the author A common use case that the public is aware of is the application of face-swapping. A target face is swapped and merged, often seamlessly on first glance view, to create an altered event. Photo by the author On a high level, Deepfake can be split into 3 sub-domains based on the focus of the media to alter. The former-mentioned use case (face-swapping) falls under Deepfake vision, where the image or video streams were targeted. Photo by the author On the other hand, Deepfake audio clone speech from third-party sources to the person in interest. In a scenario where one only communicates through phone calls, one might not be able to tell the authenticity of the sound. Photo by the author To achieve the impersonation both visually and audibly, one would have to not only look like the desired target but also sound like him. An example is shown below, where a famous actor, Morgan Freeman, is portrayed with a combination of Deepfake audio and Deepfake vision. Play the Youtube video at: https://bit.ly/3yI23zN ","date":"2022-10-10","objectID":"/deepfake-audio-with-wav2lip/:0:1","tags":["deepfake","lipsync","python"],"title":"Deepfake Audio with Wav2Lip","uri":"/deepfake-audio-with-wav2lip/"},{"categories":["nlp"],"content":"Deepfake Audio with Wav2Lip Environment Setup This article focuses on Deepfake Audio with the implementation from Github repository https://github.com/Rudrabha/Wav2Lip. The repository is based on the paper A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild published at ACM Multimedia 2020. The setup requires to run the repository includes 1. Python 3.6 Create a new virtual python environment with your preferred methods. In this example, conda command is illustrated. conda create -n wav2lip python=3.6 2. Ffmpeg pip install ffmpeg-python Particularly in Linux OS, the following installation method is preferred. sudo apt-get install ffmpeg 3. Installation of requirements.txt from the repository In this step, the repository is first cloned with the command below. git clone https://github.com/Rudrabha/Wav2Lip Note Note: In the main execution step, the python script in the repository is necessary for the actual merging of audio and video streams. Packages required, as layout in the file requirements.txt, are installed with the command below. pip install -r requirements.txt Preparation of files Largely three data source inputs are required in order to run the lip-sync with Wav2Lip. Photo by the author Model file Two models are supported out-of-the box: Wav2Lip Wav2Lip GAN While only one model is necessary for a single run, do download both for a comparison of the results. Video file For a desirable output, the input video should fulfill the following conditions. Person of interest centered and upfront in the video Person of interest with restricted body gesture and minimum head movement Person of interest with no occlusions arounds the face region (mask, shadows, hair) Preferably person of interest with still lip-movement Good lighting with not cluttered background Video with good resolution Tip Particularly, it has been found that the results are promising when the person of interest has no lip movement. This is because, through the algorithm, the mouth area would be altered to match the intonation of the speech. Having any movement from the source complicates the alteration and it might present unnatural results with visible glitches. Audio file For a desirable output, the input audio should fulfill the following conditions. Clear and succinct single source of audio (Do not have more than one person conversing with overlapping speech) Minimum/no background noises Tip As the idea is to merge the audio script to the person in interest in the video, both input files should be of similar lengths in time. Main Running Step With the files prepared and saved in local paths, it’s time to run the Wav2Lip using the script inference.py. The script is located in the path of \u003cpath-to\u003e\\Wav2Lip\\inference.py. Command should be constructed in the following manner: python inference.py --checkpoint_path \u003cpath-to-model-file\u003e --face \u003cpath-to-video-file\u003e --audio \u003cpath-to-audio-file\u003e Example of command for better clarity: python inference.py --checkpoint_path C:\\Users\\codenamewei\\deepfake\\model\\wav2lip_gan.pth --face C:\\Users\\codenamewei\\Documents\\deepfake\\data\\video_short.mp4 --audio C:\\Users\\codenamewei\\Documents\\deepfake\\data\\audio_short.wav The default and frequently used parameters are layouts as below. For a full list, check out the parameters settings from the source script. --checkpoint_path: Path to checkpoint file of supported model (Wav2Lip, Wav2Lip GAN) --face: Path to video file of supported format (mp4, avi, ...) --audio: Path to audio file of supported format (wav, flac, ...) (Optional) --nosmooth: When set, this results in no smoothing around the mouth region (Optional) --pads: When set, this adjust the range of the region to alter Parameters set in this manner: (top, bottom, left, right) Example: --pads [0, 20, 0, 0] The example above adds 20 pixels to the chin area (Optional) --static: When set to true, only the first frame will be used. Example: --static True If you are questioning which model file to use, the re","date":"2022-10-10","objectID":"/deepfake-audio-with-wav2lip/:0:2","tags":["deepfake","lipsync","python"],"title":"Deepfake Audio with Wav2Lip","uri":"/deepfake-audio-with-wav2lip/"},{"categories":["nlp"],"content":"Notes (Updated on 10th October 2022) To test the implementation of Deepfake audio, two GitHub repositories were under consideration: https://github.com/Rudrabha/Wav2Lip (Demonstrated in this article) https://github.com/Markfryazino/wav2lip-hq A promising result is shown with the out-of-the-box model of Wav2Lip. The HD model mentioned in the repository likely will deliver higher performance results. For Wav2Lip-hq, a noticeable distortion of colors on the result can be seen (as shown in the picture below). The same concern was raised in several issues as well. #6, #11. Due to that, it’s very unlikely to leverage the results generated from the repository. Photo by the author Thanks for reading! ","date":"2022-10-10","objectID":"/deepfake-audio-with-wav2lip/:0:3","tags":["deepfake","lipsync","python"],"title":"Deepfake Audio with Wav2Lip","uri":"/deepfake-audio-with-wav2lip/"},{"categories":["career"],"content":"The Epiphany: Moving from Startup to 100 Years Old Corporate","date":"2022-08-07","objectID":"/startup-to-corporate/","tags":["technology","startup","corporate","careers"],"title":"The Epiphany: Moving from A Startup to A 100 Years Old Corporate","uri":"/startup-to-corporate/"},{"categories":["career"],"content":"Introduction A year ago, I stepped away from a technology startup and joined a corporate that started back in 1923 (which marks 100 years in the coming 2023!). Note Both companies are in the field of data science realm, which many people acknowledge as a still-evolving industry. Being in the fast-paced technology field, changes are the norm, and embracing changes is the only way in moving forward. With a year of milestones after the transition, this article details the learning from the transition. Essentially, this post attempts to detail the observations of both entities, keeping it as general towards companies of a similar nature as possible. ","date":"2022-08-07","objectID":"/startup-to-corporate/:1:0","tags":["technology","startup","corporate","careers"],"title":"The Epiphany: Moving from A Startup to A 100 Years Old Corporate","uri":"/startup-to-corporate/"},{"categories":["career"],"content":"The Analogy Joining a company is very much like getting on board a boat(startup) or a ship(established corporate). Each vessel heading in one direction at one time, with crew members onboard playing a role in contributing towards the common goal. ","date":"2022-08-07","objectID":"/startup-to-corporate/:2:0","tags":["technology","startup","corporate","careers"],"title":"The Epiphany: Moving from A Startup to A 100 Years Old Corporate","uri":"/startup-to-corporate/"},{"categories":["career"],"content":"1. Problem of the same nature, but different spectrum The spectrum of chaos lies in the number of holes you have to fix at one time. Photo by the author The Boat(The Start Up) Continuing from the analogy raised, being at a startup often feels like being on a boat with multiple holes at the same time. The ability to prioritize which hole to fix will decide whether the ship will stay afloat or sink into the deep blue sea. Every day is a whole new day to prioritize and weigh which problem is worth-solving. If you are an independent contributor, it ranges either to solving an existing bug or developing a new feature. If you are a team lead, it can be a presentation for a potential lead 2 hours away or deciding the roadmap of a product. If you are in a position of wearing multiple hats, which is often very common in a startup, all of those hustles are on your plate. On some days, there are simply no options given that a problem has to solve at that particular moment. You simply have to drop everything else on your hands and attend to it. Example: an employee indicates that he is quitting, a bidding proposal is due, a single point of failure in a system, etc. The Ship(The Established Corporate) Contrary to that, being on a ship that has stayed afloat for decades and experienced countless tides, the number of holes to fix at each time is relatively lesser. This is ultimately the difference between a startup and an established corporate. Most importantly, the business is at the stage of financial stability with consistent revenue streams. With the capital to expand and scale, departments and diversifying roles have been formed over the years to address different sets of concerns. Employees at the corporate have developed the best-known methods to tackle previously faced problems. New hires went through sessions of knowledge transfer to pick up skills needed to get work done. With prior knowledge, resources, and skillful teams, the impacts of setbacks are reduced extensively. ","date":"2022-08-07","objectID":"/startup-to-corporate/:3:0","tags":["technology","startup","corporate","careers"],"title":"The Epiphany: Moving from A Startup to A 100 Years Old Corporate","uri":"/startup-to-corporate/"},{"categories":["career"],"content":"2. Changes are bound to happen. The Boat(The Start Up) With all the roller coaster rides that happen in a startup, burn-out happens and one would start to crave the stability which others have. Note Burnout is a form of exhaustion caused by constantly feeling swamped. Photo by Elisa Ventur on Unsplash In the desire for a more manageable workload, at one point one will decides to switch to the corporate. The Ship(The Established Corporate) After the lengthy yet structured on-boarding process, it takes not long to realize that reorganization still happens and the focus of business is constantly reevaluated. Internally, talent retention never gets easy, as smart people leave the company due to the lack of opportunity to work on high-profile projects or cannot relate daily work to the company’s visions. Externally, Covid disruptions (2019-2021) and the new norms of post-Covid (2022~) shift the focus of the company and directly impact the priorities of projects. For example, in the year 2022, companies including Google, Netflix, Meta either declare layoffs of employees, freeze or cut back on hiring. ","date":"2022-08-07","objectID":"/startup-to-corporate/:4:0","tags":["technology","startup","corporate","careers"],"title":"The Epiphany: Moving from A Startup to A 100 Years Old Corporate","uri":"/startup-to-corporate/"},{"categories":["career"],"content":"Summary If it’s not already obvious, both startup and established are of a similar nature. The differences one might experience in a startup or a well-established corporate are just a matter of a different spectrum, but not a different set of reality. The same problem that occurs in a startup would occur in a corporate, the difference fundamentally narrows down towards whether are you the person handling it or impacted by it. It might be out of sight because it is covered by other teams which you are not aware of due to the silo organizational structure, or senior members have regrouped and settled the problem due to how the same hiccup has appeared before. The uncertain factor of a startup is it is still at its defining stage. Each founding member hustle toward the organization’s mission. The established factor of a corporation is it has gone through the earlier stages. While transformations are still necessary, most building blocks of a company are already assembled. Work becomes routined and it brings stability to the employee pool. The idea that a startup is uncertain and that a corporate is established is a double-edged sword. If you are considering joining one or quitting one, it is crucial to consider the nature of the company with your personal context. Depending on your role given and your pursuit at that stage of your career life, these elements will decide whether the nature of an entity is a value-add or an unfavorable environment for you. Photo by the author Thanks for reading! ","date":"2022-08-07","objectID":"/startup-to-corporate/:5:0","tags":["technology","startup","corporate","careers"],"title":"The Epiphany: Moving from A Startup to A 100 Years Old Corporate","uri":"/startup-to-corporate/"},{"categories":["nlp"],"content":"Speech-to-Text Demo Trained on Conversational Speech","date":"2022-07-03","objectID":"/speech-to-text-demo/","tags":["asr","speech-to-text","huggingface"],"title":"Speech-to-Text Demo Trained on Conversational Speech","uri":"/speech-to-text-demo/"},{"categories":["nlp"],"content":"Huggingface Space Quick Demo of speech-to-text model trained with wav2vec2-conformer Try the model with Examples provided Upload audio files with extension .wav/.mp3/.flac Recordings through microphone Photo by the author Note Detailed notes about the data preparation, model training and serving will be elaborated. ","date":"2022-07-03","objectID":"/speech-to-text-demo/:0:1","tags":["asr","speech-to-text","huggingface"],"title":"Speech-to-Text Demo Trained on Conversational Speech","uri":"/speech-to-text-demo/"},{"categories":["nlp"],"content":"Side by side comparison of audio and visual data for quick understanding","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"Side by side comparison of audio and visual data for quick understanding. One aspect that will catch developers’ attention quickest when exploring Github repositories is an informative and succinct readme, often complemented by informative visuals aids. Visuals aids are great in relaying any content most straightforwardly. When used properly, it allows faster try-out, adoption of the scripts with out-of-the-box guidelines. Here are some examples of how it can be used. ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:0:0","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"1 Introduction Illustration of concept Photo by the author Display of workflow Photo by the author ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:1:0","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"2 Takeaway This post focus on how to display images effectively in a markdown file. ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:2:0","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"3 Contents 3.1 Method to display the image 3.2 Tradeoffs in where to host the image 3.3 The engaging element – Gif 3.4 Does it work with video? ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:3:0","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"3.1 Method to display the image The preferred method to display an image is as shown below. \u003cdiv align=\"center\"\u003e \u003cimg alt=\"text\" src=\"url\" width=\"500\" height=\"500\"\u003e\u003cbr\u003e \u003csup\u003eThis it the caption of the image\u003csup\u003e \u003c/div\u003e If you are familiar with HTML, you will realize that the snippet of code is in HTML format. There are 5 parameters to tinker with: align: Alignment of the image to left, center, or right src: Relative path or URL pointing to the image alt: Text for the image area, shown when the image is not found width: Width of the image in pixels height: Height of the image in pixels Note: Each of these parameters has to be wrapped in a double quote. Example: In particular, the resizing of image works best by just defining one of the image size (width/height). The other side will be adjusted adaptively along with the changes, maintaining the aspect ratio of the image. This allows the image to be easily presented in a new resolution with no distortions. Alternatively, the simplest format to insert an image into a markdown file is as shown below ![text](relative path / url to the image) While it works perfectly fine, it does not allow granular controls such as changing the orientation or adjusting the size of the image. Example: In practice, both formats are used interchangeably where the latter comes as a quick fix. ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:3:1","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"3.2 Tradeoffs in where to host the image An immediate next question when comes to append an image in a markdown file will be where to host the image. There are two options: Upload the image to cloud storage and expose it as a public URL Add the image into a sub-location in the repository Photo by the author Both options come with tradeoffs, where the downsides are mentioned below. Photo by the author With images placed in the same repository, it’s important to get the relative path right. The relative path pointing towards the image should always be initiated from the markdown file referring to it. Examples are shown as below: Photo by the author ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:3:2","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"3.3 The engaging element – Gif Gif image can be displayed in the mentioned format too. Animated Gif is useful in illustrating steps or procedures. With consideration of internet bandwidths and the size of the gifs to be embedded, moderate use of Gifs will boost the engagement of the readers. ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:3:3","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"3.4 Does it work with video? On rare occasions, some might have the intention to include video in a markdown file. An effective way of doing this is to have a good image representation while embedding the video URL. Option 1 \u003cdiv align=\"center\"\u003e \u003ca href=\"video_url\"\u003e\u003cimg src=\"image_url\"\u003e\u003c/a\u003e \u003c/div\u003e Option 2 [![Watch the video](image_url)](video_url) Thanks for reading. Till next time! ","date":"2022-02-14","objectID":"/understand-audio-data-with-computer-vision-background/:3:4","tags":["nlp","computer-vision","data"],"title":"Understand Audio Data with Computer Vision Background","uri":"/understand-audio-data-with-computer-vision-background/"},{"categories":["nlp"],"content":"Python-based libraries to download Youtube videos for NLP use cases","date":"2022-01-05","objectID":"/youtube-to-text-with-speech-recognition-in-python/","tags":["nlp","youtube","speech recognition"],"title":"Youtube to Text with Speech Recognition in Python","uri":"/youtube-to-text-with-speech-recognition-in-python/"},{"categories":["nlp"],"content":"Python-based libraries to download Youtube videos for NLP use cases ","date":"2022-01-05","objectID":"/youtube-to-text-with-speech-recognition-in-python/:0:0","tags":["nlp","youtube","speech recognition"],"title":"Youtube to Text with Speech Recognition in Python","uri":"/youtube-to-text-with-speech-recognition-in-python/"},{"categories":["nlp"],"content":"1 Introduction In the effort to build a conversational speech-to-text NLP model, I started to dive in on the methods to retrieve audio data from Youtube platform. The goal is to have data pairing between the audio and text snippet as the input data source. Photo by the author There are two libraries to retrieve sets of audio and text data from the Youtube platform. you-get library youtube2text library ","date":"2022-01-05","objectID":"/youtube-to-text-with-speech-recognition-in-python/:1:0","tags":["nlp","youtube","speech recognition"],"title":"Youtube to Text with Speech Recognition in Python","uri":"/youtube-to-text-with-speech-recognition-in-python/"},{"categories":["nlp"],"content":"2 You-get Library A straightforward method is by using the you-get library. The python-based library can be easily installed with pip. pip install you-get The python-based library use terminal commands for the operations. The audio file can be retrieved in various outputs (.mp4, .webm) while the texts are presented in the SubRip subtitle output file (.srt). Using the library after installation is straightforward. Get information on which sources to download with the following command in a terminal. you-get -i https://www.youtube.com/watch?v=2M_kCCcNDts Photo by the author Proceed to download with the command below. Change the itag value to a selected tag with the preferred output type (.mp4, .webm). you-get --itag=137 https://www.youtube.com/watch?v=2M_kCCcNDts Alternatively, running the command without specifying the tag value will download the default in the list. you-get https://www.youtube.com/watch?v=2M_kCCcNDts The subtitle file is in the following manner. Photo by the author Notice how the texts are all lowercase and do not separate with the end of sentence punctuation. Due to that, sequential steps of post-processing work have to be performed to get working pairs of audio and text. ","date":"2022-01-05","objectID":"/youtube-to-text-with-speech-recognition-in-python/:2:0","tags":["nlp","youtube","speech recognition"],"title":"Youtube to Text with Speech Recognition in Python","uri":"/youtube-to-text-with-speech-recognition-in-python/"},{"categories":["nlp"],"content":"3 Youtube2text Library Youtube2text library is designed to get a suitable format for the audio\u003c\u003etext pairing. The library supports three functionalities at the time of writing. Retrieve Youtube URL as audio and text output Download Youtube audio in an audio file format (.wav, .flac) Extract the audio file to text output Install the library by pip with the following command. pip install youtube2text To retrieve a youtube URL as audio and text output, run the following command in a python environment. from youtube2text import Youtube2Text converter = Youtube2Text() converter.url2text(\"https://www.youtube.com/watch?v=Ad9Q8rM0Am0\u0026t=114s\") The library currently supports audio in wav or flac format and text in csv format, where the output is stored in the sub-folders of the designated path or default path \u003cHOMEPATH\u003e\\youtube2text. Photo by the author The layout of the directories is listed below. Audio folder contains the audio file as a whole, while audio-chunks folder stores snippets of audio file matching to the metadata in the text file. Csv file in the text folder is the output of the translation from audio to text. \u003cOwn Path\u003e or \u003cHOME_DIRECTORY\u003e/youtube2text │ ├── audio/ │ └── 2022Jan02_011802.wav | ├── audio-chunks/ │ └── 2022Jan02_011802 │ ├── chunk1.wav │ ├── chunk2.wav │ └── chunk3.wav │ └── text/ └── 2022Jan02_011802.csv The goal of mine is to prepare audio and translated text to train a custom Automatic Speech Recognition (ASR) model. Any attempts in using large language pretrained model would require the newly added audio data to be sampled in a desired frequency (example: 16 kHz). The selected sampling rate should match to the ones where the existing NLP model has been trained with. With that context, it’s important for the audio data retrieving process to allows the toggling of the sample rate. Youtube2text is designed to factor the toggling of audio sample rate. converter.url2audio(urlpath = \"https://www.youtube.com/watch?v=rFYcvrKkr90\", audiosamplingrate = 22000) Let’s take a glimpse into the text file. The text file contains 2 columns: text and wav. Metadata of audio chunk mapping to a text sentence is provided side by side. Photo by the author Text file outputs are arranged in a manner to allow the correction of any sentence if needed. Since the audio is translated to text with existing speech recognition model, the text generated is highly dependent on the quality of the audio output. It might not be all the times where audio is articulated in a precise manner. To put things into context, imagine that a Ted talk with speaker who articulates with zero background noise would be interpretable than webinars hosting more than one person with background music. With a few attempts, it is obvious that the text requires manual inspection and correction to produce high quality translated text data. Do expect to spend time and effort in this process to get high quality translated text. While it might be tedious at times, this helps to ensure a good raw source of data is prepared for subsequent NLP model training.The replaying of audio chunk alongside the text column makes it easier to find the correspond part pairing to the audio output. The column stating the file is important for the task such as ASR use case. In the latter step to train the model, the data preparation step reads in audio file from the specific audio path and preprocess the vector embeddings. Otherwise, if the metadata of wav information is not needed, the column stating the file can be eliminated easily by deleting the column in a single step. Photo by the author Check out the python notebook for more examples of using the youtube2text library. Thanks for reading. ","date":"2022-01-05","objectID":"/youtube-to-text-with-speech-recognition-in-python/:3:0","tags":["nlp","youtube","speech recognition"],"title":"Youtube to Text with Speech Recognition in Python","uri":"/youtube-to-text-with-speech-recognition-in-python/"},{"categories":["nlp"],"content":"4 Resources https://github.com/soimort/you-get https://github.com/codenamewei/youtube2text ","date":"2022-01-05","objectID":"/youtube-to-text-with-speech-recognition-in-python/:4:0","tags":["nlp","youtube","speech recognition"],"title":"Youtube to Text with Speech Recognition in Python","uri":"/youtube-to-text-with-speech-recognition-in-python/"},{"categories":["system"],"content":"Why and how to use Jupyter Notebooks in VS Code","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"Why and how to use Jupyter Notebooks in VS Code ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:0:0","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"1 Introduction It’s no secret that Jupyter Notebook is the go-to IDE in the data science field. The cell nature of Jupyter allows instant running of a block of code snippet and manifest of the output. Photo by the author It works seamlessly well with the nature of data analysis operation, specifically in the way where the subsequent lines of code highly depend on the scrutinization of the current cell output. While using Jupyter Notebook is great by itself, the features can be greatly enhanced when used in VS Code with the Jupyter Extension. ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:1:0","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"2 Why use Jupyter Notebooks in VS Code? Shallow learning curve To begin with, a developer had utilized VS Code at some point in code development. Hence, there is a very shallow learning curve to start using Jupyter notebooks in VS Code. Photo by the author Seamlessly swaps between files of different format Photo by the author A project folder, in general, contains files of different formats. For example, python notebooks(.ipynb) are used for data analysis and modeling steps, while native python scripts(.py) are preferred when deploying models. Not to mention there are also sources of data input and output in the form of CSV or excel. By setting VS Code as the go-to-workspace, alternating between files is effortless. Subsequently editing each file can be done side by side with the optimized view being presented according to the file format. VS Code works especially well with markdown files as shown below. Photo by the author Built-in terminal in VS Code The ability to open a terminal in the VS Code itself is especially useful. With this feature, one can run git operations and other text-based commands in the same interface. Photo by the author This truly shows the powerful features in VS Code to allow day-to-day operations to be carried out in an all-in-one platform. ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:2:0","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"3 How to user Jupyter Notebooks in VS Code? As the layout for Jupyter in VS Code varies compared to native web browsers, this section introduces 4 fundamental functionalities to ensure an easy adoption for Jupyter Notebook in VS Code. Install Jupyter extension Create Jupyter notebook Change Conda environment Change cell type ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:3:0","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"3.1 Install Jupyter Extension Installing of Jupyter extension provides notebook support in the IDE. Run VS Code, and open up Extension View by either Clicking on the Extensions icon in the Activity Bar, or Photo by the author Using shortcut keys (Ctrl+Shift+X) Search with the keyword Jupyter and install the first option in the list. Photo by the author ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:3:1","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"3.2 Create Jupyter Notebook There are two methods to create a new Jupyter Notebook. Open the command palette with shortcut keys (Ctrl + Shift + P). Search for Jupyter: Create New Jupyter Notebook Photo by the author Click on the new file icon, and name the new file ends with .ipynb extension Photo by the author ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:3:2","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"3.3 Change Conda Environment To select Conda virtual environment for the notebook, simply click on the environment tab in the top right corner. Subsequently, select the desired environment from a drop-down list of Conda environments. Photo by the author Do take note that this step is performed with a notebook opened in VS Code. ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:3:3","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":["system"],"content":"3.4 Change cell type To change the cell type of any cell, simply click on the tab located at the bottom right of the cell. A drop-down list of cell types will appear for selection. Photo by the author Here, the most fundamental operations to use Jupyter Notebooks in VS Code are introduced. These 4 functionalities are sufficient for most of the daily usages. Check out VS Code documentation for other functionalities in mind. Do take note that some time is needed to get familiarized with the interface. This is especially true if the user has been using Jupyter notebook in the native browser. Yet, the learning shall not possess any major difficulties and can be polished with frequent usages. Thanks for reading! I hope you experience a boost of productivity with this setup! ","date":"2021-12-01","objectID":"/the-perks-of-using-jupyter-notebook-in-vs-code/:3:4","tags":["python","jupyter","vscode","editor"],"title":"The Perks of using Jupyter Notebook in VS Code","uri":"/the-perks-of-using-jupyter-notebook-in-vs-code/"},{"categories":null,"content":"To be added. ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"}]